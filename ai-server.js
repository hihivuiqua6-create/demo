require('dotenv').config();
const express = require('express');
const cors = require('cors');
const Groq = require('groq-sdk');

const app = express();
const PORT = process.env.PORT || 3000;

// Khá»Ÿi táº¡o Groq client
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

// LÆ°u conversation theo session
const conversations = new Map();

app.use(cors());
app.use(express.json());

// Middleware kiá»ƒm tra API key (optional, Ä‘á»ƒ debug)
app.use((req, res, next) => {
  if (!process.env.GROQ_API_KEY) {
    console.warn('âš ï¸ GROQ_API_KEY chÆ°a Ä‘Æ°á»£c set trong Environment Variables!');
  }
  next();
});

// Endpoint chat chÃ­nh - thÃ´ng minh nhá» Groq LLM
app.post('/api/chat', async (req, res) => {
  try {
    const { message, sessionId = 'default' } = req.body;

    if (!message?.trim()) {
      return res.status(400).json({
        success: false,
        error: 'Message is required'
      });
    }

    // Láº¥y hoáº·c táº¡o history cho session
    if (!conversations.has(sessionId)) {
      conversations.set(sessionId, []);
    }
    const history = conversations.get(sessionId);

    // ThÃªm tin nháº¯n user vÃ o history
    history.push({ role: 'user', content: message.trim() });

    // Láº¥y 12 tin nháº¯n gáº§n nháº¥t Ä‘á»ƒ lÃ m context (tiáº¿t kiá»‡m token)
    const context = history.slice(-12);

    // Gá»i Groq API
    const completion = await groq.chat.completions.create({
      messages: [
        {
          role: 'system',
          content: `Báº¡n lÃ  má»™t AI Assistant siÃªu thÃ´ng minh, hÃ i hÆ°á»›c, thÃ¢n thiá»‡n, tráº£ lá»i tá»± nhiÃªn báº±ng tiáº¿ng Viá»‡t (hoáº·c ngÃ´n ngá»¯ ngÆ°á»i dÃ¹ng dÃ¹ng). 
          LuÃ´n há»¯u Ã­ch, chÃ­nh xÃ¡c, Ä‘Ã´i khi troll nháº¹ nhÃ ng. DÃ¹ng kiáº¿n thá»©c rá»™ng, suy nghÄ© logic, tráº£ lá»i chi tiáº¿t nhÆ°ng ngáº¯n gá»n khi cáº§n.
          Nhá»› context tá»« lá»‹ch sá»­ há»™i thoáº¡i Ä‘á»ƒ tráº£ lá»i liá»n máº¡ch.`
        },
        ...context  // gá»­i lá»‹ch sá»­ lÃ m context
      ],
      model: 'llama-3.3-70b-versatile',          // model máº¡nh + nhanh, free tier ok
      // model: 'mixtral-8x7b-32768',             // náº¿u muá»‘n thay Ä‘á»•i
      temperature: 0.7,                           // sÃ¡ng táº¡o vá»«a pháº£i
      max_tokens: 1200,
      top_p: 0.9,
      stream: false
    });

    const aiResponse = completion.choices[0]?.message?.content?.trim() || 'KhÃ´ng cÃ³ pháº£n há»“i tá»« AI. Thá»­ láº¡i nhÃ©!';

    // ThÃªm response cá»§a AI vÃ o history
    history.push({ role: 'assistant', content: aiResponse });

    // Giá»›i háº¡n history Ä‘á»ƒ khÃ´ng trÃ n RAM
    if (history.length > 40) {
      history.splice(0, history.length - 30);
    }

    res.json({
      success: true,
      response: aiResponse,
      source: 'Groq LLM (Llama 3.3 70B)',
      timestamp: new Date().toISOString(),
      sessionId
    });

  } catch (error) {
    console.error('Groq API error:', error.message);
    res.status(500).json({
      success: false,
      error: 'Lá»—i khi gá»i AI. CÃ³ thá»ƒ API key sai hoáº·c rate limit.',
      details: error.message
    });
  }
});

// Láº¥y lá»‹ch sá»­ há»™i thoáº¡i
app.get('/api/history/:sessionId', (req, res) => {
  const { sessionId } = req.params;
  const history = conversations.get(sessionId) || [];
  res.json({
    success: true,
    history,
    count: history.length
  });
});

// XÃ³a lá»‹ch sá»­
app.delete('/api/history/:sessionId', (req, res) => {
  const { sessionId } = req.params;
  conversations.delete(sessionId);
  res.json({
    success: true,
    message: 'ÄÃ£ xÃ³a lá»‹ch sá»­ há»™i thoáº¡i'
  });
});

// Health check cho Render
app.get('/health', (req, res) => {
  res.json({
    status: 'ok',
    message: 'AI Server Groq-integrated is running',
    version: '4.0',
    groq_key_set: !!process.env.GROQ_API_KEY,
    timestamp: new Date().toISOString()
  });
});

// Root endpoint
app.get('/', (req, res) => {
  res.json({
    name: 'Super Smart AI Chat Server (Groq Powered)',
    version: '4.0',
    description: 'Chat vá»›i AI thÃ´ng minh gáº§n giá»‘ng Grok, dÃ¹ng Llama 3.3 70B',
    features: [
      'Context-aware conversation',
      'Natural & humorous responses',
      'Tiáº¿ng Viá»‡t mÆ°á»£t mÃ ',
      'Session-based memory',
      'Groq API integration'
    ],
    endpoints: {
      'POST /api/chat': 'Gá»­i tin nháº¯n chat',
      'GET /api/history/:sessionId': 'Xem lá»‹ch sá»­',
      'DELETE /api/history/:sessionId': 'XÃ³a lá»‹ch sá»­',
      'GET /health': 'Kiá»ƒm tra server'
    }
  });
});

// Khá»Ÿi Ä‘á»™ng server
app.listen(PORT, () => {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ðŸ§  SUPER SMART AI SERVER (GROQ) v4.0 STARTED ðŸ§  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸš€ Port: ${PORT}
ðŸŒ Environment: ${process.env.NODE_ENV || 'development'}
ðŸ”‘ Groq Key: ${process.env.GROQ_API_KEY ? 'SET' : 'MISSING - Check Env Vars!'}
Model: llama-3.3-70b-versatile
Ready to chat siÃªu thÃ´ng minh! ðŸ’¬
  `);
});

// Graceful shutdown cho Render
process.on('SIGTERM', () => {
  console.log('SIGTERM received â†’ Shutting down gracefully...');
  process.exit(0);
});
